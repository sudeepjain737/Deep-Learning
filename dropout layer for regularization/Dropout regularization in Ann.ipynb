{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9750181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7762aaf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>0.1694</td>\n",
       "      <td>0.2328</td>\n",
       "      <td>0.2684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1018</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.2154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.1178</td>\n",
       "      <td>0.1258</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.1123</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1843</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8   \\\n",
       "0    0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1    0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2    0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3    0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4    0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n",
       "204  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n",
       "205  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n",
       "206  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  0.1123  0.1945   \n",
       "207  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  0.1400  0.1843   \n",
       "\n",
       "         9   ...      51      52      53      54      55      56      57  \\\n",
       "0    0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1    0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2    0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3    0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4    0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.2684  ...  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065  0.0115   \n",
       "204  0.2154  ...  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034  0.0032   \n",
       "205  0.2529  ...  0.0160  0.0029  0.0051  0.0062  0.0089  0.0140  0.0138   \n",
       "206  0.2354  ...  0.0086  0.0046  0.0126  0.0036  0.0035  0.0034  0.0079   \n",
       "207  0.2354  ...  0.0146  0.0129  0.0047  0.0039  0.0061  0.0040  0.0036   \n",
       "\n",
       "         58      59  60  \n",
       "0    0.0090  0.0032   R  \n",
       "1    0.0052  0.0044   R  \n",
       "2    0.0095  0.0078   R  \n",
       "3    0.0040  0.0117   R  \n",
       "4    0.0107  0.0094   R  \n",
       "..      ...     ...  ..  \n",
       "203  0.0193  0.0157   M  \n",
       "204  0.0062  0.0067   M  \n",
       "205  0.0077  0.0031   M  \n",
       "206  0.0036  0.0048   M  \n",
       "207  0.0061  0.0115   M  \n",
       "\n",
       "[208 rows x 61 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sonar_dataset.csv',header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "addcd9d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "     ..\n",
       "56    0\n",
       "57    0\n",
       "58    0\n",
       "59    0\n",
       "60    0\n",
       "Length: 61, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7065458c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['R', 'M'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[60].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a09e1b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[60].replace({'R' : 0, 'M' : 1},inplace = True)\n",
    "df[60].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a159f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop([60],axis = 1)\n",
    "y = df[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "918b0d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>0.1694</td>\n",
       "      <td>0.2328</td>\n",
       "      <td>0.2684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.0157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1018</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.2154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.1178</td>\n",
       "      <td>0.1258</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.1123</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1843</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8   \\\n",
       "0    0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1    0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2    0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3    0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4    0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n",
       "204  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n",
       "205  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n",
       "206  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  0.1123  0.1945   \n",
       "207  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  0.1400  0.1843   \n",
       "\n",
       "         9   ...      50      51      52      53      54      55      56  \\\n",
       "0    0.2111  ...  0.0232  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180   \n",
       "1    0.2872  ...  0.0125  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140   \n",
       "2    0.6194  ...  0.0033  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316   \n",
       "3    0.1264  ...  0.0241  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050   \n",
       "4    0.4459  ...  0.0156  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072   \n",
       "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.2684  ...  0.0203  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065   \n",
       "204  0.2154  ...  0.0051  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034   \n",
       "205  0.2529  ...  0.0155  0.0160  0.0029  0.0051  0.0062  0.0089  0.0140   \n",
       "206  0.2354  ...  0.0042  0.0086  0.0046  0.0126  0.0036  0.0035  0.0034   \n",
       "207  0.2354  ...  0.0181  0.0146  0.0129  0.0047  0.0039  0.0061  0.0040   \n",
       "\n",
       "         57      58      59  \n",
       "0    0.0084  0.0090  0.0032  \n",
       "1    0.0049  0.0052  0.0044  \n",
       "2    0.0164  0.0095  0.0078  \n",
       "3    0.0044  0.0040  0.0117  \n",
       "4    0.0048  0.0107  0.0094  \n",
       "..      ...     ...     ...  \n",
       "203  0.0115  0.0193  0.0157  \n",
       "204  0.0032  0.0062  0.0067  \n",
       "205  0.0138  0.0077  0.0031  \n",
       "206  0.0079  0.0036  0.0048  \n",
       "207  0.0036  0.0061  0.0115  \n",
       "\n",
       "[208 rows x 60 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ce5bed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "203    1\n",
       "204    1\n",
       "205    1\n",
       "206    1\n",
       "207    1\n",
       "Name: 60, Length: 208, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68ada309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2, random_state= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1acdf017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166, 60)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b0429c",
   "metadata": {},
   "source": [
    "# Model without Dropout Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea080a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape = (60,)),\n",
    "    keras.layers.Dense(60, activation='relu'),\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dense(15, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = \"adam\",\n",
    "    loss = \"binary_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca83aa17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6871 - accuracy: 0.5602\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 0s/step - loss: 0.6694 - accuracy: 0.5602\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 769us/step - loss: 0.6586 - accuracy: 0.5602\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 0s/step - loss: 0.6475 - accuracy: 0.5602\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6341 - accuracy: 0.5723\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6235 - accuracy: 0.6265\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6119 - accuracy: 0.6747\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5983 - accuracy: 0.6747\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5815 - accuracy: 0.7108\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.7289\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5501 - accuracy: 0.7349\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5332 - accuracy: 0.7289\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7349\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7651\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7831\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.8072\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7892\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.8133\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4112 - accuracy: 0.8494\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3977 - accuracy: 0.8012\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3826 - accuracy: 0.8133\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3734 - accuracy: 0.8795\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3608 - accuracy: 0.8434\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3502 - accuracy: 0.8614\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.3443 - accuracy: 0.8735\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3433 - accuracy: 0.8434\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8795\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8976\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3457 - accuracy: 0.8133\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3148 - accuracy: 0.8855\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3005 - accuracy: 0.8554\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8253\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.2943 - accuracy: 0.8976\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.2784 - accuracy: 0.9096\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.2962 - accuracy: 0.8494\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3045 - accuracy: 0.8614\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.2829 - accuracy: 0.8795\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.2638 - accuracy: 0.9036\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.2614 - accuracy: 0.9157\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.2542 - accuracy: 0.8916\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.2552 - accuracy: 0.9217\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.9096\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.2414 - accuracy: 0.8916\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.2339 - accuracy: 0.9157\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.2368 - accuracy: 0.9217\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.2424 - accuracy: 0.8976\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.2258 - accuracy: 0.9036\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.2182 - accuracy: 0.9337\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.2147 - accuracy: 0.9157\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.2088 - accuracy: 0.9277\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.2040 - accuracy: 0.9277\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.2009 - accuracy: 0.9337\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1966 - accuracy: 0.9337\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.2005 - accuracy: 0.9277\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1879 - accuracy: 0.9398\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1869 - accuracy: 0.9398\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1851 - accuracy: 0.9398\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1818 - accuracy: 0.9398\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1767 - accuracy: 0.9518\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1992 - accuracy: 0.9398\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.2025 - accuracy: 0.8976\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1734 - accuracy: 0.9458\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1829 - accuracy: 0.9217\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1712 - accuracy: 0.9398\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1548 - accuracy: 0.9578\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1567 - accuracy: 0.9518\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1459 - accuracy: 0.9578\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1413 - accuracy: 0.9639\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1357 - accuracy: 0.9639\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1369 - accuracy: 0.9699\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1325 - accuracy: 0.9639\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1376 - accuracy: 0.9578\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1385 - accuracy: 0.9578\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1347 - accuracy: 0.9578\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1277 - accuracy: 0.9699\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1197 - accuracy: 0.9639\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1136 - accuracy: 0.9759\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1156 - accuracy: 0.9699\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1172 - accuracy: 0.9578\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1208 - accuracy: 0.9578\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1246 - accuracy: 0.9578\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0973 - accuracy: 0.9639\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1171 - accuracy: 0.9639\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0938 - accuracy: 0.9759\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0966 - accuracy: 0.9819\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0939 - accuracy: 0.9940\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0909 - accuracy: 0.9699\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1000 - accuracy: 0.9819\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0825 - accuracy: 0.9940\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0830 - accuracy: 0.9819\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0902 - accuracy: 0.9880\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0778 - accuracy: 0.9819\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0761 - accuracy: 0.9940\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0731 - accuracy: 0.9940\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0705 - accuracy: 0.9819\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0663 - accuracy: 0.9940\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 0.9880\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0682 - accuracy: 0.9880\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0680 - accuracy: 0.9880\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0567 - accuracy: 0.9880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ba6b90fa60>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8994c286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step - loss: 0.8181 - accuracy: 0.7381\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8180838823318481, 0.738095223903656]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d77458e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    }
   ],
   "source": [
    "y_predicted = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df8bc5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for i in y_predicted:\n",
    "    if(i < 0.5):\n",
    "        y_pred.append(0)\n",
    "    else:\n",
    "        y_pred.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f2aa5ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 0, 1, 0, 1, 1, 0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f1f6154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58     0\n",
       "63     0\n",
       "35     0\n",
       "19     0\n",
       "59     0\n",
       "56     0\n",
       "83     0\n",
       "105    1\n",
       "121    1\n",
       "76     0\n",
       "Name: 60, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19e4f10d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 0, 0, 1, 0, 1, 1, 1]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a6337bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206    1\n",
       "132    1\n",
       "5      0\n",
       "55     0\n",
       "78     0\n",
       "117    1\n",
       "70     0\n",
       "46     0\n",
       "142    1\n",
       "1      0\n",
       "Name: 60, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "476fe12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.62      0.73        24\n",
      "           1       0.64      0.89      0.74        18\n",
      "\n",
      "    accuracy                           0.74        42\n",
      "   macro avg       0.76      0.76      0.74        42\n",
      "weighted avg       0.78      0.74      0.74        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e19b30e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = tf.math.confusion_matrix(y_test,y_pred)\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(cm,annot = True,fmt = 'd',cmap='Blues')\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee48f75d",
   "metadata": {},
   "source": [
    "# Model with Dropout Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae286e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dropout = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape = (60,)),\n",
    "    keras.layers.Dense(60, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(15, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_dropout.compile(\n",
    "    optimizer = \"adam\",\n",
    "    loss = \"binary_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60551d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 1s 2ms/step - loss: 0.6792 - accuracy: 0.6145\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5542\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6976 - accuracy: 0.5361\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.5422\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5181\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7008 - accuracy: 0.5361\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6829 - accuracy: 0.5723\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5361\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6990 - accuracy: 0.4699\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7012 - accuracy: 0.5482\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6815 - accuracy: 0.5723\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7083 - accuracy: 0.5060\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7026 - accuracy: 0.5361\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5241\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6861 - accuracy: 0.5422\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.5422\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6795 - accuracy: 0.5482\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6744 - accuracy: 0.5602\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6873 - accuracy: 0.5663\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6813 - accuracy: 0.5482\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6825 - accuracy: 0.5181\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6786 - accuracy: 0.5663\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6725 - accuracy: 0.5482\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5542\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6639 - accuracy: 0.6024\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6766 - accuracy: 0.5422\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6860 - accuracy: 0.5422\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6872 - accuracy: 0.5120\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5060\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6750 - accuracy: 0.5542\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6654 - accuracy: 0.5663\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6623 - accuracy: 0.5904\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6743 - accuracy: 0.5843\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6811 - accuracy: 0.5542\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6607 - accuracy: 0.5542\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6576 - accuracy: 0.5663\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6577 - accuracy: 0.5361\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6603 - accuracy: 0.5783\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6570 - accuracy: 0.5843\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6404 - accuracy: 0.6325\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6426 - accuracy: 0.6205\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6434 - accuracy: 0.5663\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6560 - accuracy: 0.5783\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6510 - accuracy: 0.5843\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6480 - accuracy: 0.5843\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6388 - accuracy: 0.6566\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6464 - accuracy: 0.5843\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6223 - accuracy: 0.6386\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6312 - accuracy: 0.6446\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6468 - accuracy: 0.6024\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6231 - accuracy: 0.6627\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6362 - accuracy: 0.6084\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6457 - accuracy: 0.5783\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.5964\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6082 - accuracy: 0.6687\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6131 - accuracy: 0.6446\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6274 - accuracy: 0.6265\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6072 - accuracy: 0.7169\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6329 - accuracy: 0.6205\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5924 - accuracy: 0.6867\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5875 - accuracy: 0.6386\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5749 - accuracy: 0.6687\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6026 - accuracy: 0.6928\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6225 - accuracy: 0.6145\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5924 - accuracy: 0.6807\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5786 - accuracy: 0.7048\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6004 - accuracy: 0.6325\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5713 - accuracy: 0.7229\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5717 - accuracy: 0.7410\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5891 - accuracy: 0.6506\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5834 - accuracy: 0.7349\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5563 - accuracy: 0.7169\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5884 - accuracy: 0.6928\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.7530\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5386 - accuracy: 0.6988\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5328 - accuracy: 0.7169\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5766 - accuracy: 0.6928\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.6566\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5969 - accuracy: 0.6325\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7651\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5521 - accuracy: 0.7349\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.7349\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5471 - accuracy: 0.7289\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.7289\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7410\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7590\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5545 - accuracy: 0.7169\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 0s/step - loss: 0.5355 - accuracy: 0.6988\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.7651\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7711\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 0s/step - loss: 0.4961 - accuracy: 0.7349\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.7229\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.7169\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7952\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7651\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.7771\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5549 - accuracy: 0.7289\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4910 - accuracy: 0.8133\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7771\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.8072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ba74af3eb0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dropout.fit(x_train,y_train,epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42da5400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step - loss: 0.5670 - accuracy: 0.7619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5669739842414856, 0.761904776096344]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dropout.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82aae3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    }
   ],
   "source": [
    "y_predicted_dropout = model_dropout.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ecf9d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dropout = []\n",
    "for i in y_predicted_dropout:\n",
    "    if(i < 0.5):\n",
    "        y_pred_dropout.append(0)\n",
    "    else:\n",
    "        y_pred_dropout.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "636bf14d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 0, 0, 1, 0, 0, 1, 1]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_dropout[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c918a477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206    1\n",
       "132    1\n",
       "5      0\n",
       "55     0\n",
       "78     0\n",
       "117    1\n",
       "70     0\n",
       "46     0\n",
       "142    1\n",
       "1      0\n",
       "Name: 60, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af84fe1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.75      0.78        24\n",
      "           1       0.70      0.78      0.74        18\n",
      "\n",
      "    accuracy                           0.76        42\n",
      "   macro avg       0.76      0.76      0.76        42\n",
      "weighted avg       0.77      0.76      0.76        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred_dropout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e07dbc99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = tf.math.confusion_matrix(y_test,y_pred_dropout)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(cm, annot = True , fmt = 'd')\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecefce7",
   "metadata": {},
   "source": [
    "## using dropout layer test accuracy increased from 0.74 to 0.76"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
